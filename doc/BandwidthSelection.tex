\documentclass{article}

\usepackage{amssymb,amsmath,amsfonts,eurosym,geometry,ulem,graphicx,caption,color,setspace,sectsty,comment,footmisc,caption,natbib,pdflscape,subfigure,array,hyperref,upgreek,bbm}

\normalem


\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{verbatim}
\usepackage{setspace}
\usepackage{ulem}
\usepackage{textpos}
\usepackage{changepage}
\usepackage{url}
%\usepackage{multirow}


%\usepackage{hyperref}
%\usepackage{xcolor}
%\hypersetup{colorlinks, linkcolor=blue, citecolor=blue}

%\renewcommand{\sout}[1]{}
%\renewcommand{\textbf}{}
%\renewcommand{\bf}{}

\newcommand{\tsout}[1]{\text{\sout{$#1$}}}


\tolerance=5000
\newtheorem{remark}{Remark}
\def\mb{\mathbf}
\def\iid{\mathrm{i.i.d. }}
\def\bs{\boldsymbol}
\def\tbf{\textbf}
\def\t{^{\top}}
\def\bSig{\bs{\Sigma}}
\newcommand{\mcitet}[1]{\mbox{\citet{#1}}}
\newcommand{\mcitep}[1]{\mbox{\citep{#1}}}

\DeclareMathOperator{\vect}{vec}
\DeclareMathOperator{\vecth}{vech}


\onehalfspacing
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{example}{Example}
%\newenvironment{proof}[1][Proof]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}

\newcommand{\ind}{\mathbbm{1}}

\newcommand{\R}{\mathbb{R}}
\newtheorem{assumption}{Assumption}

\newtheorem{hyp}{Hypothesis}
\newtheorem{subhyp}{Hypothesis}[hyp]
\renewcommand{\thesubhyp}{\thehyp\alph{subhyp}}

\newcommand{\red}[1]{{\color{red} #1}}
\newcommand{\blue}[1]{{\color{blue} #1}}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\arraybackslash\hspace{0pt}}m{#1}}


\title{Bandwidth Selection of Kernel Estimator}
\author{Jasmine Hao}
\date{\today}

\begin{document}

\maketitle

\section{Kernel estimator}
The bandwidth selection follows the lecture notes by \cite{Sun2013}.

If $f$ is smooth in a small neighborhood $[x-h/2,x+h/2]$ of $x$, we can ustify the following approximation:
$h f(x) \approx \int_{x-h/2}^{x+h/2} f(u) d u $ by the mean theorem.
The estimator of $f(x)$ is given by $\hat{f}(x) = \frac{1}{nh} \sum_{i=1}^n \{ X_i \in (x-h/2,x+h/2) \}$

The kernel estimator is therefore
\[
\hat{f}(x) = \frac{1}{nh} \sum_{i=1}^n K(\frac{x - X_i}{h}),
\]
where $K(\cdot)$ is a kernel function with the assumptions.
The example kernel functions can be found in Hansen's note on non-parametric estimation \cite{Hansen2009}.

Hansen, B. E. (2009). Lecture Notes on Nonparametrics. Retrieved from \url{https://www.ssc.wisc.edu/~bhansen/718/NonParametrics1.pdf}.

Higher-order kernels are obtained by multiplying a second-order kernel by an $(\nu/2 - 1)$-th order polynomial in $u$: Explicit formulae for the general polynomial family can be found in B. Hansen (Econometric Theory, 2005), and for the Gaussian family inWand and Schucany (Canadian Journal of Statistics, 1990).
\[ \begin{split}
\end{split} \]
\begin{table}[!htbp]
  \begin{center}
  \caption{Kernel Functions}
  \begin{tabular}{lllll}
    \hline    \hline
    Kernel & $K(u)$ & $R(k)$ & $\kappa_2(k)$ & $eff(k)$  \\ \hline
    Uniform & $\frac{1}{2} \ind \{ |u| \le 1 \}$ & 1/2 &  1/3 & 1.0758\\
    Triangle & $(1 - |u|) \ind \{ |u| \le 1 \}$  &- & -& - \\
    Epanechnikov & $\frac{3}{4} (1 - u^2) \ind \{ |u| \le 1 \}$ & 3/5 & 1/5 & 1.0\\
    Quartic(Biweight) & $\frac{15}{16} (1 - u^2)^2 \ind\{ |u| \le 1 \}$ & 5/7 & 1/7 & 1.0061\\
    Triweight & $\frac{35}{32} (1 - u^2)^3 \ind\{ |u| \le 1 \}$ & 350 / 429 & 1/9 & 1.0135 \\
    Gaussian & $\frac{1}{\sqrt{2\pi}} \exp(-\frac{x^2}{2})$ & $1/\sqrt{2\pi}$ & 1 &  1.0513 \\
    Cosinus & $\frac{\pi}{4} \cos(\frac{\pi}{2}u)\ind\{ |u| \le 1 \}$ &-&-&- \\
    \hline
  \end{tabular}

\caption{Fourth Order Kernel Functions}
\begin{tabular}{lllll}
  \hline    \hline
Kernel & $K(u)$ & $R(k)$ & $\kappa_2(k)$ & $eff(k)$  \\ \hline
Epanechnikov & $\frac{15}{8}\frac{3}{4}(1 - \frac{7}{3}u^2)(1-u^2) \ind \{ |u| \le 1 \} $ & $5/4$ & -1/21 & 1.00\\
Biweight & $\frac{7}{4}\frac{15}{16} (1 - 3*u^2) (1 - u^2)^2 \ind\{ |u| \le 1 \} $ & 805/572 & -1/33 & 1.0056 \\
Triweight & $\frac{27}{16} \frac{35}{32} (1 - 11/3 u^2) (1 - u^2)^3 \ind\{ |u| \le 1 \}$  & 3780 / 2431 & -3/143 & 1.0134 \\
  \hline
\end{tabular}
\end{center}

\end{table}

\section{Bandwidth Selection}
\subsection{Estimation Bias}
The bias of a kernel density of order $\nu$ estimator is
\[ Bias(\hat{f}(x)) = E\hat{f}(x) - f(x) = \frac{1}{\nu!} f^{(\nu)}(x) h^{\nu} \kappa_{\nu} (k) + o(h^{\nu}). \]


\subsection{Estimation Variance}
The kernel estimator is a linear estimator, and $\kappa(\frac{X_i - x}{u})$ is i.i.d, then \[\begin{split} Var(\hat{f}(x)) & = \frac{1}{nh^2} E k \left( \frac{X_i - x}{h} \right)^2 - \frac{1}{n} \left( \frac{1}{h} Ek\left( \frac{X_i - x}{h} \right) \right)^2 \\
& = \frac{f(x)R(k)}{nh} + O(1/n)
\end{split}\]

\subsection{Mean squared error}
The measure of precision is the mean squared error
\[\begin{split}
AMSE(\hat{f}(x)) & = E(\hat{f}(x) - f(x))^2 \\
& = \frac{\kappa_\nu^2(k)}{(\nu!)^2} f^{(\nu)}(x)^2 h^{2\nu} + \frac{f(x)R(k)}{nh}
\end{split}\]
Global measure of precision is the asymptotic mean integrated squared error(AMISE):
\[\begin{split}
AMISE(\hat{f}(x)) & = \int_{-\inf}^{\inf} AMSE(\hat{f}(x)) dx \\
& = \frac{\kappa_\nu^2(k)}{(\nu!)^2} R( f^{(\nu)}) h^{2\nu} + \frac{f(x)R(k)}{nh}
\end{split}\]
\subsection{Asymptotically optimal bandwidth}

\subsection{Asymptotically optimal kernel}
\subsection{Silverman Rule-of-thumb bandwidth selection}
\[ \begin{split}
h & =  \hat{\sigma} C_\nu(k) n^{-1/(2\nu+1)}  \\
 & = 2 \hat{\sigma} n^{-1/(2\nu+1)} \left( \frac{\pi^{1/2}(\nu!)^3 R(k)}{2\nu(2\nu)! \kappa_\nu^2(k)} \right)^{1/(2\nu+1)} \end{split}\]

The rule of thumb constant constant can be looked up in the table.
\begin{table}[!htbp]
  \begin{centering}
    \caption{Rule of thumb constant $C_\nu(k)$ for single-variate}
  \begin{tabular}{lrrr}
    \hline \hline
    \tbf{Kernel} & $\nu = 2$ & $\nu = 4$ & $\nu = 6$ \\
    \hline
    Epanechnikov & 2.34 & 3.03 & 3.53 \\
    Biweight & 2.78 & 3.39 & 3.84 \\
    Triweight & 3.15 & 3.73 & 4.13 \\
    Gaussian & 1.06 & 1.08 & 1.08 \\ \hline
  \end{tabular}
  \end{centering}
\end{table}

\bibliographystyle{apalike}
\bibliography{ref}
\end{document}
